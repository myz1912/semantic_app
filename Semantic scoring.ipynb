{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a402826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ef8c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semanticScore(tokenizer, model, sentences):\n",
    "    # initialize dictionary to store tokenized sentences\n",
    "    tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # encode each sentence and append to dictionary\n",
    "        new_tokens = tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                           truncation=True, padding='max_length',\n",
    "                                           return_tensors='pt')\n",
    "        tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "        tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "    # reformat list of tensors into single tensor\n",
    "    tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "    \n",
    "    # getting last_hidden_state using mean pooling to calculate cosine similarity\n",
    "    outputs = model(**tokens)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    masked_embeddings = embeddings * mask\n",
    "    mean_pooled = torch.sum(masked_embeddings, 1) / torch.clamp(mask.sum(1), min=1e-9)\n",
    "    # convert from PyTorch tensor to numpy array\n",
    "    mean_pooled = mean_pooled.detach().numpy()\n",
    "\n",
    "    return mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20e13cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textClean(text):\n",
    "    import string\n",
    "    return text.translate(text.maketrans('', '', string.punctuation)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7a560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM(sentences, answer):\n",
    "    '''\n",
    "    return \n",
    "    Exact Match for bigram\n",
    "    '''\n",
    "    answer = textClean(answer)\n",
    "    answer_token = answer.split()\n",
    "    answer_bigrams = [answer_token[i:i+2] for i in range(len(answer_token) - 1)]\n",
    "    res = []\n",
    "    for sentence in sentences:\n",
    "        count = 0\n",
    "        sentence = textClean(sentence)\n",
    "        sentence_token = sentence.split()\n",
    "        if len(sentence_token) < 2:\n",
    "            res.append(0)\n",
    "        else:\n",
    "            for i in range(len(sentence) - 1):\n",
    "                bigram = sentence_token[i:i+2]\n",
    "                if bigram in answer_bigrams:\n",
    "                    count += 1\n",
    "            res.append(round(100*count/(len(sentence_token)-1), 2))\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101b8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(sentences, answer):\n",
    "    '''\n",
    "    return the f1 score\n",
    "    '''\n",
    "    answer_token = set(textClean(answer).split())\n",
    "    res = []\n",
    "    for sentence in sentences:\n",
    "        sentence_token = set(textClean(sentence).split())\n",
    "        common_token = sentence_token & answer_token\n",
    "        if not common_token:\n",
    "            res.append(0)\n",
    "        else:\n",
    "            precision = len(common_token) / len(sentence_token)\n",
    "            recall = len(common_token) / len(answer_token)\n",
    "            res.append(round((2 * precision * recall/(precision + recall))*100,2))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3840ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['A Type I error is a false positive (claiming something has happened when it hasnâ€™t), and a Type II error is a false negative (claiming nothing has happened when it actually has).',\n",
    "            'A type I error (false-positive) occurs if an investigator rejects a null hypothesis that is actually true in the population; a type II error (false-negative) occurs if the investigator fails to reject a null hypothesis that is actually false in the population.',\n",
    "            'In statistical hypothesis testing, a type I error is the mistaken rejection of an actually true null hypothesis (also known as a \"false positive\" finding or conclusion; example: \"an innocent person is convicted\"), while a type II error is the mistaken acceptance of an actually false null hypothesis (also known as a \"false negative\" finding or conclusion; example: \"a guilty person is not convicted\").',\n",
    "            'A Type I error is a false positive, and a Type II error is a false negative.']\n",
    "# answer is at index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e68097d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "# model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c711a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"./bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a459b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.save_pretrained(\"./bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b05558aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('./bert_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./bert_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184c3fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = semanticScore(tokenizer, model, sentences)\n",
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2625779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_answers</th>\n",
       "      <th>Bigram Exact Match</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>semantic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Type I error is a false positive (claiming s...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A type I error (false-positive) occurs if an i...</td>\n",
       "      <td>14.63</td>\n",
       "      <td>36.36</td>\n",
       "      <td>81.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In statistical hypothesis testing, a type I er...</td>\n",
       "      <td>19.05</td>\n",
       "      <td>37.04</td>\n",
       "      <td>81.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Type I error is a false positive, and a Type...</td>\n",
       "      <td>93.75</td>\n",
       "      <td>68.97</td>\n",
       "      <td>89.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sample_answers  Bigram Exact Match  \\\n",
       "0  A Type I error is a false positive (claiming s...              100.00   \n",
       "1  A type I error (false-positive) occurs if an i...               14.63   \n",
       "2  In statistical hypothesis testing, a type I er...               19.05   \n",
       "3  A Type I error is a false positive, and a Type...               93.75   \n",
       "\n",
       "   F1 score  semantic_score  \n",
       "0    100.00          100.00  \n",
       "1     36.36           81.38  \n",
       "2     37.04           81.12  \n",
       "3     68.97           89.17  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'sample_answers':sentences, \n",
    "              'Bigram Exact Match': EM(sentences, sentences[0]),\n",
    "              'F1 score': f1(sentences, sentences[0]),\n",
    "              'semantic_score': [round(score*100, 2) for score in cosine_similarity([mean_pooled[0]], mean_pooled).reshape(-1,)]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
